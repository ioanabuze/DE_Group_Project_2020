{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "number_cores = 8\n",
    "memory_gb = 24\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setMaster('local[{}]'.format(number_cores))\n",
    "        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - wordcloud\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
      "    certifi-2019.11.28         |           py36_0         149 KB  conda-forge\n",
      "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
      "    wordcloud-1.6.0            |   py36h516909a_0         184 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  wordcloud          conda-forge/linux-64::wordcloud-1.6.0-py36h516909a_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
      "  certifi                                         pkgs/main --> conda-forge\n",
      "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "wordcloud-1.6.0      | 184 KB    | ##################################### | 100% \n",
      "openssl-1.1.1d       | 2.1 MB    | ##################################### | 100% \n",
      "ca-certificates-2019 | 145 KB    | ##################################### | 100% \n",
      "certifi-2019.11.28   | 149 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snorkel in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: scikit-learn<0.22.0,>=0.20.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (0.21.3)\n",
      "Requirement already satisfied: networkx<3.0,>=2.2 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (2.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (1.18.1)\n",
      "Requirement already satisfied: pandas<0.25.0,>=0.24.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (0.24.2)\n",
      "Requirement already satisfied: torch<1.2.0,>=1.1.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (1.1.0)\n",
      "Requirement already satisfied: tensorboardX<2.0,>=1.6 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (1.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.29.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (4.43.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from snorkel) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from scikit-learn<0.22.0,>=0.20.2->snorkel) (0.14.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from networkx<3.0,>=2.2->snorkel) (4.4.1)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from pandas<0.25.0,>=0.24.0->snorkel) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from pandas<0.25.0,>=0.24.0->snorkel) (2.8.1)\n",
      "Requirement already satisfied: six in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from tensorboardX<2.0,>=1.6->snorkel) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from tensorboardX<2.0,>=1.6->snorkel) (3.11.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorboardX<2.0,>=1.6->snorkel) (45.2.0.post20200210)\n"
     ]
    }
   ],
   "source": [
    "!pip install snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'to_int_label_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e10ed347acae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# from textblob import TextBlob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabeling_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeling_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabelModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPandasLFApplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkLFApplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Programmatic data set labeling: LF creation, models, and analysis utilities.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLFAnalysis\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLFApplier\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPandasLFApplier\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/snorkel/labeling/analysis.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_int_label_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelingFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'to_int_label_array'"
     ]
    }
   ],
   "source": [
    "# from textblob import TextBlob\n",
    "from snorkel.labeling import labeling_function, labeling_function, LabelModel, PandasLFApplier\n",
    "from snorkel.labeling.apply.spark import SparkLFApplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "\n",
    "# Make a subset of our dataframe using pandas and keep only the columns we need, remove rows with NaN\n",
    "# Ideally we need to do this part done using Spark\n",
    "amazon_reviews_dataset_pd_df = pd.read_csv(\"/project/DE_Group_Project_2020/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\")\n",
    "amazon_reviews_dataset_pd_df = pd.concat([amazon_reviews_dataset_pd_df['reviews.rating'],amazon_reviews_dataset_pd_df['reviews.text']], axis=1)\n",
    "amazon_reviews_dataset_pd_df = amazon_reviews_dataset_pd_df.dropna()\n",
    "amazon_reviews_dataset_pd_df.rename(columns={\"reviews.rating\": \"reviews_rating\", \"reviews.text\": \"reviews_text\"}, inplace=True)\n",
    "amazon_reviews_dataset_pd_df\n",
    "\n",
    "# Convert pandas DF to spark dataframe\n",
    "amazon_reviews_dataset_sql_context = sqlContext.createDataFrame(amazon_reviews_dataset_pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp view for maniputing the data using SQL queries\n",
    "amazon_reviews_dataset_sql_context.createOrReplaceTempView('amazon_reviews')\n",
    "\n",
    "# Spliting the review text by review level, these will be the basis for learning information about the data that\n",
    "# can be used for creating heuristics for our labeling functions. \n",
    "\n",
    "amazon_reviews_level1 = sqlContext.sql(\"SELECT reviews_text FROM amazon_reviews where reviews_rating == 1\")\n",
    "amazon_reviews_level2 = sqlContext.sql(\"SELECT reviews_text FROM amazon_reviews where reviews_rating == 2\")\n",
    "amazon_reviews_level3 = sqlContext.sql(\"SELECT reviews_text FROM amazon_reviews where reviews_rating == 3\")\n",
    "amazon_reviews_level4 = sqlContext.sql(\"SELECT reviews_text FROM amazon_reviews where reviews_rating == 4\")\n",
    "amazon_reviews_level5 = sqlContext.sql(\"SELECT reviews_text FROM amazon_reviews where reviews_rating == 5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'sentiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a19c78d0f8c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamazon_reviews_level1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1304\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1305\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sentiment'"
     ]
    }
   ],
   "source": [
    "Y_dev = amazon_reviews_level1.sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-6210b7207b2c>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-6210b7207b2c>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    reviewone_wc = WordCloud(width=512,height=512).generate(reviewone)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Visualise the 5 different reviews WordCloud and figure other ways to quantify frequency of words\n",
    "# From - https://towardsdatascience.com/spam-classifier-in-python-from-scratch-27a98ddd8e73\n",
    "\n",
    "# WorldCloud - Review == 1 \n",
    "reviewone = ' '.join(list(amazon_reviews_level1)\n",
    "reviewone_wc = WordCloud(width=512,height=512).generate(reviewone)\n",
    "\n",
    "plt.figure(figsize = (10,8), facecolor = 'k')\n",
    "plt.imshow(reviewone_wc)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set voting values.\n",
    "RATINGONE = 0\n",
    "RATINGTWO = 1 \n",
    "RATINGTHREE = 2\n",
    "RATINGFOUR = 3\n",
    "RATINGFIVE = 4\n",
    "\n",
    "ABSTAIN = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "from snorkel.preprocess import preprocessor\n",
    "\n",
    "# Common good words \n",
    "GOOD = r\"\\bjew (love|great|good|easy|happy|nice|fun|pretty|works|better|well|ok)\"\n",
    "BAD = r\"\\bjew (old|junk|useless|failded|slow|nothing)\"\n",
    "\n",
    "# labelling functions for five different rating tiers \n",
    "def good(x):\n",
    "  if re.search(GOOD, x) else ABSTAIN\n",
    "     return RATINGTHREE if TextBlob() else ABSTAIN\n",
    "     return RATINGFOUR if  else ABSTAIN\n",
    "     return RATINGFIVE if  else ABSTAIN\n",
    "  if re.search(BAD, x) else ABSTAIN\n",
    "     return RATINGTWO if  else ABSTAIN\n",
    "     return RATINGTHRE if  else ABSTAIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
